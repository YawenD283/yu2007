View(image_accuracy)
ggplot(image_accuracy, aes(x = correct_image, y = accuracy)) +
geom_line(color = "blue", size = 1) +
geom_point(color = "red", size = 2) +
labs(x = "Correct Image",
y = "Accuracy")
ggplot(image_accuracy, aes(x = correct_image, y = accuracy)) +
geom_line(color = "blue", size = 1) +
geom_point(color = "red", size = 2) +
labs(x = "Image",
y = "Accuracy")
ggplot(image_accuracy, aes(x = correct_image, y = accuracy)) +
geom_line(color = "blue", size = 1) +
geom_point(color = "red", size = 2) +
scale_x_continuous(breaks = seq(1, 18, 1))+
labs(x = "Image",
y = "Accuracy")
ggplot(image_accuracy, aes(x = correct_image, y = accuracy)) +
geom_line(color = "skyblue", size = 1) +
geom_point(color = "pink", size = 2) +
scale_x_continuous(breaks = seq(1, 18, 1))+
labs(x = "Image",
y = "Accuracy")
ggplot(image_accuracy, aes(x = correct_image, y = accuracy)) +
geom_line(color = "forestgreen", size = 1) +
geom_point(color = "pink", size = 2) +
scale_x_continuous(breaks = seq(1, 18, 1))+
labs(x = "Image",
y = "Accuracy")
ggplot(image_accuracy, aes(x = correct_image, y = accuracy)) +
geom_line(color = "forestgreen", size = 1) +
geom_point(color = "yellow", size = 2) +
scale_x_continuous(breaks = seq(1, 18, 1))+
labs(x = "Image",
y = "Accuracy")
ggplot(image_accuracy, aes(x = correct_image, y = accuracy)) +
geom_line(color = "forestgreen", size = 1) +
geom_point(color = "blue", size = 2) +
scale_x_continuous(breaks = seq(1, 18, 1))+
labs(x = "Image",
y = "Accuracy")
ggplot(image_accuracy, aes(x = correct_image, y = accuracy)) +
geom_line(color = "forestgreen", size = 1) +
geom_point(color = "skyblue4", size = 2) +
scale_x_continuous(breaks = seq(1, 18, 1))+
labs(x = "Image",
y = "Accuracy")
ggplot(image_accuracy, aes(x = correct_image, y = accuracy)) +
geom_line(color = "forestgreen", size = 1) +
geom_point(color = "skyblue3", size = 2) +
scale_x_continuous(breaks = seq(1, 18, 1))+
labs(x = "Image",
y = "Accuracy")
response_time <- cleaned_data %>%
summarize(
mean_response_time = mean(response_time, na.rm = TRUE),
median_response_time = median(response_time, na.rm = TRUE),
sd_response_time = sd(response_time, na.rm = TRUE)
)
print(response_time)
response_time <- cleaned_data %>%
group_by(correct) %>%
summarize(
mean_response_time = mean(response_time, na.rm = TRUE),
sd_response_time = sd(response_time, na.rm = TRUE)
)
print(response_time_by_group)
response_time <- cleaned_data %>%
group_by(correct) %>%
summarize(
mean_response_time = mean(response_time, na.rm = TRUE),
sd_response_time = sd(response_time, na.rm = TRUE)
)
print(response_time)
response_time <- cleaned_data %>%
group_by(correct) %>%
summarize(
mean_response_time = mean(response_time, na.rm = TRUE),
median_response_time = median(response_time, na.rm = TRUE),
sd_response_time = sd(response_time, na.rm = TRUE)
)
print(response_time)
ggplot(cleaned_data, aes(x = correct, y = response_time)) +
geom_boxplot() +
labs(title = "Response Times by Condition", x = "Condition", y = "Response Time (ms)")
ggplot(cleaned_data, aes(x = correct, y = response_time)) +
geom_boxplot() +
labs(title = "Response Times by Correctness", x = "Correctness", y = "Response Time (ms)")
t_test <- t.test(
response_time ~ correct,
data = cleaned_data
)
print(t_test)
### Data Preparation
#### Load Relevant Libraries and Functions
library(jsonlite)
library(dplyr)
library(ggplot2)
#### Import data
setwd("/Users/yawendong/Documents/GitHub/psych final project/pilot-data")
files <- list.files(pattern = "\\.csv$")
all_data <- lapply(files, read.csv) %>% bind_rows()
#### Data exclusion / filtering
selected_data <- all_data %>% select(correct_choice, correct_image, response_letter, correct, response_time)
cleaned_data <- na.omit(selected_data)
cleaned_data$correct <- as.logical(cleaned_data$correct)
#### Prepare data for analysis - create columns etc.
accuracy <- mean(cleaned_data$correct, na.rm = TRUE)
print(paste("Overall Accuracy: ", round(accuracy * 100, 2), "%"))
image_accuracy <- cleaned_data %>%
group_by(correct_image) %>%
summarize(accuracy = mean(correct, na.rm = TRUE))
ggplot(image_accuracy, aes(x = correct_image, y = accuracy)) +
geom_line(color = "forestgreen", size = 1) +
geom_point(color = "skyblue3", size = 2) +
scale_x_continuous(breaks = seq(1, 18, 1))+
labs(x = "Image",
y = "Accuracy")
response_time <- cleaned_data %>%
group_by(correct) %>%
summarize(
mean_response_time = mean(response_time, na.rm = TRUE),
median_response_time = median(response_time, na.rm = TRUE),
sd_response_time = sd(response_time, na.rm = TRUE)
)
print(response_time)
t_test <- t.test(
response_time ~ correct,
data = cleaned_data
)
print(t_test)
### Data Preparation
#### Load Relevant Libraries and Functions
library(jsonlite)
library(dplyr)
library(ggplot2)
library(pwr)
#### Import data
setwd("/Users/yawendong/Documents/GitHub/psych final project/pilot-data")
files <- list.files(pattern = "\\.csv$")
all_data <- lapply(files, read.csv) %>% bind_rows()
#### Data exclusion / filtering
selected_data <- all_data %>% select(correct_choice, correct_image, response_letter, correct, response_time)
cleaned_data <- na.omit(selected_data)
cleaned_data$correct <- as.logical(cleaned_data$correct)
#### Prepare data for analysis - create columns etc.
### Data Preparation
#### Load Relevant Libraries and Functions
library(jsonlite)
library(dplyr)
library(ggplot2)
library(pwr)
library(effectsize)
### Data Preparation
#### Load Relevant Libraries and Functions
library(jsonlite)
library(dplyr)
library(ggplot2)
library(pwr)
install.packages('effectsize')
#### Import data
setwd("/Users/yawendong/Documents/GitHub/psych final project/pilot-data")
files <- list.files(pattern = "\\.csv$")
all_data <- lapply(files, read.csv) %>% bind_rows()
#### Data exclusion / filtering
selected_data <- all_data %>% select(correct_choice, correct_image, response_letter, correct, response_time)
cleaned_data <- na.omit(selected_data)
cleaned_data$correct <- as.logical(cleaned_data$correct)
#### Prepare data for analysis - create columns etc.
### Data Preparation
#### Load Relevant Libraries and Functions
library(jsonlite)
library(dplyr)
library(ggplot2)
library(pwr)
library(effectsize)
#### Import data
setwd("/Users/yawendong/Documents/GitHub/psych final project/pilot-data")
files <- list.files(pattern = "\\.csv$")
all_data <- lapply(files, read.csv) %>% bind_rows()
#### Data exclusion / filtering
selected_data <- all_data %>% select(correct_choice, correct_image, response_letter, correct, response_time)
cleaned_data <- na.omit(selected_data)
cleaned_data$correct <- as.logical(cleaned_data$correct)
#### Prepare data for analysis - create columns etc.
cohens_d <- cohens_d(response_time ~ correct, data = cleaned_data)
conhens_d
cohens_d <- cohens_d(response_time ~ correct, data = cleaned_data)
cohens_d
pwr_result <- pwr.t.test(
d = 0.5,               # Cohen's d (effect size)
sig.level = 0.05,      # Alpha level
power = 0.80,          # Desired power
type = "two.sample"    # Two-sample t-test
)
print(pwr_result)
cohens_d <- cohens_d(response_time ~ correct, data = cleaned_data)
cohens_d
pwr_result <- pwr.t.test(
d = 0.53,
sig.level = 0.05,
power = 0.80,
type = "two.sample"
)
print(pwr_result)
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
options(stringsAsFactors = FALSE)
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(lsr)
install.packages('lsr')
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(lsr)
library(ggthemes)
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(lsr)
library(ggthemes)
# Just Study 1
d <- read_excel ("data/S1_Subway.xlsx")
d$Orientation <- factor(d$Orientation, levels = c("Toward", "Away"))
View(d)
d = d %>%
mutate(
DIRECTION = as.factor(DIRECTION),
STN_NUMBER = as.factor(STN_NUMBER),
STN_NAME = factor(STN_NAME, levels = c("SPAD", "STG", "B-Y", "SHER"))
)
View(d)
str(d)
d %>%
group_by(DIRECTION, STN_NAME) %>%
summarise(Count = n()) %>%
arrange(DIRECTION, STN_NAME) %>%
print()
d_num <- d %>%
group_by(DIRECTION, STN_NAME) %>%
summarise(Count = n()) %>%
ungroup()
print(d_num)
anova_results <- aov(CLOSENESS ~ DIRECTION * STN_NAME, data = d)
anova <- aov(DISTANCE ~ DIRECTION * STN_NAME, data = d)
summary(anova)
etaSquared(anova)
etaSquared(anova)
## reproduce the findings for St. George
st_george <- d %>%
filter(STN_NAME == "STG")
## reproduce the findings for St. George
st_george <- d %>%
filter(STN_NAME == "STG")
st_george %>%
group_by(DIRECTION) %>%
summarise(mean = mean(DISTANCE))
st_george_anova = aov(data = st_george,
DISTANCE ~ DIRECTION)
summary(st_george_anova)
## reproduce the findings for St. George
st_george <- d %>%
filter(STN_NAME == "STG")
st_george %>%
group_by(DIRECTION) %>%
summarise(mean = mean(DISTANCE))
st_george_anova = aov(data = st_george,
DISTANCE ~ DIRECTION)
summary(st_george_anova)
etaSquared(st_george_anova)
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
options(stringsAsFactors = FALSE)
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(lsr)
library(ggthemes)
# Just Study 1
d <- read_excel ("data/S1_Subway.xlsx")
d = d %>%
mutate(
DIRECTION = as.factor(DIRECTION),
STN_NUMBER = as.factor(STN_NUMBER),
STN_NAME = factor(STN_NAME, levels = c("SPAD", "STG", "B-Y", "SHER"))
)
str(d)
d_num <- d %>%
group_by(DIRECTION, STN_NAME) %>%
summarise(Count = n()) %>%
ungroup()
print(d_num)
anova <- aov(DISTANCE ~ DIRECTION * STN_NAME, data = d)
summary(anova)
etaSquared(anova)
## reproduce the findings for St. George
st_george <- d %>%
filter(STN_NAME == "STG")
st_george %>%
group_by(DIRECTION) %>%
summarise(mean = mean(DISTANCE))
st_george_anova = aov(data = st_george,
DISTANCE ~ DIRECTION)
summary(st_george_anova)
etaSquared(st_george_anova)
## do the same for Spadina
## do the same for Bloor-Yonge
## do the same for Sherbourne
## do the same for Spadina
spadina <- d %>%
filter(STN_NAME == "SPAD")
spadina %>%
group_by(DIRECTION) %>%
summarise(mean = mean(DISTANCE))
spadina_anova = aov(data = spadina,
DISTANCE ~ DIRECTION)
summary(spadina_anova)
etaSquared(spadina_anova)
View(all_data)
View(d)
## do the same for Bloor-Yonge
by <- d %>%
filter(STN_NAME == "B-Y")
by %>%
group_by(DIRECTION) %>%
summarise(mean = mean(DISTANCE))
by_anova = aov(data = by,
DISTANCE ~ DIRECTION)
summary(by_anova)
etaSquared(by_anova)
## do the same for Sherbourne
sherbourne <- d %>%
filter(STN_NAME == "SHER")
sherbourne %>%
group_by(DIRECTION) %>%
summarise(mean = mean(DISTANCE))
sherbourne_anova = aov(data = sherbourne,
DISTANCE ~ DIRECTION)
summary(sherbourne_anova)
etaSquared(sherbourne_anova)
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(lsr)
library(ggthemes)
library(ggplot2)
plot_data <- d %>%
group_by(DIRECTION, STN_NAME) %>%
summarise(
mean_closeness = mean(CLOSENESS, na.rm = TRUE),
se_closeness = sd(CLOSENESS, na.rm = TRUE) / sqrt(n())
) %>%
ungroup()
plot_data <- d %>%
group_by(DIRECTION, STN_NAME) %>%
summarise(
mean_distance = mean(DISTANCE, na.rm = TRUE),
se_distance = sd(DISTANCE, na.rm = TRUE) / sqrt(n())
) %>%
ungroup()
ggplot(plot_data, aes(x = STN_NAME, y = mean_distance, group = DIRECTION, color = DIRECTION)) +
geom_line(size = 1) +
geom_point(size = 3) +
geom_errorbar(aes(ymin = mean_distance - se_distance, ymax = mean_distance + se_distance), width = 0.2) +
scale_color_manual(values = c("black", "gray")) +
labs(
title = "Subjective Distance Ratings by Orientation and Station",
x = "Station",
y = "Subjective Distance"
) +
theme_minimal() +
theme(
legend.title = element_blank(),
legend.position = "bottom"
)
plot_data <- d %>%
group_by(DIRECTION, STN_NAME) %>%
summarise(
mean_distance = mean(DISTANCE, na.rm = TRUE),
se_distance = sd(DISTANCE, na.rm = TRUE) / sqrt(n())
) %>%
ungroup()
ggplot(plot_data, aes(x = STN_NAME, y = mean_distance, group = DIRECTION, color = DIRECTION)) +
geom_line(size = 1) +
geom_point(size = 3) +
geom_errorbar(aes(ymin = mean_distance - se_distance, ymax = mean_distance + se_distance), width = 0.2) +
scale_color_manual(values = c("gray", "black")) +
labs(
title = "Subjective Distance Ratings by Orientation and Station",
x = "Station",
y = "Subjective Distance"
) +
theme_minimal() +
theme(
legend.title = element_blank(),
legend.position = "bottom"
)
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
options(stringsAsFactors = FALSE)
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(lsr)
library(ggthemes)
library(ggplot2)
# Just Study 1
d <- read_excel ("data/S1_Subway.xlsx")
d = d %>%
mutate(
DIRECTION = as.factor(DIRECTION),
STN_NUMBER = as.factor(STN_NUMBER),
STN_NAME = factor(STN_NAME, levels = c("SPAD", "STG", "B-Y", "SHER"))
)
str(d)
d_num <- d %>%
group_by(DIRECTION, STN_NAME) %>%
summarise(Count = n()) %>%
ungroup()
print(d_num)
anova <- aov(DISTANCE ~ DIRECTION * STN_NAME, data = d)
summary(anova)
etaSquared(anova)
## reproduce the findings for St. George
st_george <- d %>%
filter(STN_NAME == "STG")
st_george %>%
group_by(DIRECTION) %>%
summarise(mean = mean(DISTANCE))
st_george_anova = aov(data = st_george,
DISTANCE ~ DIRECTION)
summary(st_george_anova)
etaSquared(st_george_anova)
## do the same for Spadina
spadina <- d %>%
filter(STN_NAME == "SPAD")
spadina %>%
group_by(DIRECTION) %>%
summarise(mean = mean(DISTANCE))
spadina_anova = aov(data = spadina,
DISTANCE ~ DIRECTION)
summary(spadina_anova)
etaSquared(spadina_anova)
## do the same for Bloor-Yonge
by <- d %>%
filter(STN_NAME == "B-Y")
by %>%
group_by(DIRECTION) %>%
summarise(mean = mean(DISTANCE))
by_anova = aov(data = by,
DISTANCE ~ DIRECTION)
summary(by_anova)
etaSquared(by_anova)
## do the same for Sherbourne
sherbourne <- d %>%
filter(STN_NAME == "SHER")
sherbourne %>%
group_by(DIRECTION) %>%
summarise(mean = mean(DISTANCE))
sherbourne_anova = aov(data = sherbourne,
DISTANCE ~ DIRECTION)
summary(sherbourne_anova)
etaSquared(sherbourne_anova)
plot_data <- d %>%
group_by(DIRECTION, STN_NAME) %>%
summarise(
mean_distance = mean(DISTANCE, na.rm = TRUE),
se_distance = sd(DISTANCE, na.rm = TRUE) / sqrt(n())
) %>%
ungroup()
ggplot(plot_data, aes(x = STN_NAME, y = mean_distance, group = DIRECTION, color = DIRECTION)) +
geom_line(size = 1) +
geom_point(size = 3) +
geom_errorbar(aes(ymin = mean_distance - se_distance, ymax = mean_distance + se_distance), width = 0.2) +
scale_color_manual(values = c("gray", "black")) +
labs(
title = "Subjective Distance Ratings by Orientation and Station",
x = "Station",
y = "Subjective Distance"
) +
theme_minimal() +
theme(
legend.title = element_blank(),
legend.position = "bottom"
)
plot <- d %>%
group_by(DIRECTION, STN_NAME) %>%
summarise(
mean_distance = mean(DISTANCE, na.rm = TRUE),
se_distance = sd(DISTANCE, na.rm = TRUE) / sqrt(n())
) %>%
ungroup()
ggplot(plot, aes(x = STN_NAME, y = mean_distance, group = DIRECTION, color = DIRECTION)) +
geom_line(size = 1) +
geom_point(size = 3) +
geom_errorbar(aes(ymin = mean_distance - se_distance, ymax = mean_distance + se_distance), width = 0.2) +
scale_color_manual(values = c("gray", "black")) +
labs(
title = "Subjective Distance Ratings by Orientation and Station",
x = "Station",
y = "Subjective Distance"
) +
theme_minimal() +
theme(
legend.title = element_blank(),
legend.position = "bottom"
)
